{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "good-comments-guardian",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a607e5c62425421c8a44d4ebd5beb896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_05457b92c98d4b97bc28eefddeb0beb6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ae4dfa64ec345e8a3a81cf7a956437a",
              "IPY_MODEL_99f5f3dd94cb4a748bcb4d8d2384f2a2"
            ]
          }
        },
        "05457b92c98d4b97bc28eefddeb0beb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ae4dfa64ec345e8a3a81cf7a956437a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7baba7b4193346d29a17ea97c0e3735a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 441,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 441,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4052e2623404dd4bb9b4ec255bc19cf"
          }
        },
        "99f5f3dd94cb4a748bcb4d8d2384f2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a6b70438d4843baad6ab6c9e928d87a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 441/441 [00:00&lt;00:00, 755B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8958d0b3797f430e8fde1be470448fbd"
          }
        },
        "7baba7b4193346d29a17ea97c0e3735a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4052e2623404dd4bb9b4ec255bc19cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a6b70438d4843baad6ab6c9e928d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8958d0b3797f430e8fde1be470448fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da454c10f10e4fbba5c50c804ee53806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8518f8009a0439cb203fcee4d689123",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_129b5df777b14773ba3d8ad51a061ffc",
              "IPY_MODEL_bb2ef1f89162461d870ce3af1be929ca"
            ]
          }
        },
        "e8518f8009a0439cb203fcee4d689123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "129b5df777b14773ba3d8ad51a061ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8858eda43e94cd69fd6e7c6eaf58ae7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 113629967,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 113629967,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c89154234e5b4c26bd9bf8388d403bf4"
          }
        },
        "bb2ef1f89162461d870ce3af1be929ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4da3b853f6624db48df4f73887273b6f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 114M/114M [00:02&lt;00:00, 39.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2629d5b97fed45b6bb8a3067af5bd2e0"
          }
        },
        "e8858eda43e94cd69fd6e7c6eaf58ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c89154234e5b4c26bd9bf8388d403bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4da3b853f6624db48df4f73887273b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2629d5b97fed45b6bb8a3067af5bd2e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "651035ad5e6b44d0baa189a02d92cc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2ce76d54d074969831f312e515e33d4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc7298213f9845d2aa9df877902a2cc9",
              "IPY_MODEL_ca7dd0c7d1c543c199a6b147fca70355"
            ]
          }
        },
        "b2ce76d54d074969831f312e515e33d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc7298213f9845d2aa9df877902a2cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d453f62c26c742e0955082ddd04ac11f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 371391,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 371391,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a738c20fb7642a1b7582b6f6c09830b"
          }
        },
        "ca7dd0c7d1c543c199a6b147fca70355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a12fefdf86da42939a4e4b2d2b0bf034",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 371k/371k [00:00&lt;00:00, 594kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfaea0b84d3c4a40a1179c0483cd3082"
          }
        },
        "d453f62c26c742e0955082ddd04ac11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a738c20fb7642a1b7582b6f6c09830b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a12fefdf86da42939a4e4b2d2b0bf034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfaea0b84d3c4a40a1179c0483cd3082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff042a1a6ad2405fac06a8df93ae9b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_551ac9ccbffa4d17a937d74e64335728",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fafe51672b8e4870a532bee729fffa6d",
              "IPY_MODEL_16838df5b306474b958fafd5df027f63"
            ]
          }
        },
        "551ac9ccbffa4d17a937d74e64335728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fafe51672b8e4870a532bee729fffa6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7a4397b83e640f0bb60fa2b7b336c37",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77779,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77779,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_00db2e740dd54198b1cec893c330d139"
          }
        },
        "16838df5b306474b958fafd5df027f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e29e567fe8194e6886a268bf6d2fb197",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 77.8k/77.8k [00:16&lt;00:00, 4.83kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcb38bbd771f45b39683a3f58a61fe80"
          }
        },
        "d7a4397b83e640f0bb60fa2b7b336c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "00db2e740dd54198b1cec893c330d139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e29e567fe8194e6886a268bf6d2fb197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcb38bbd771f45b39683a3f58a61fe80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osori/korean-hate-comments/blob/master/good_comments_guardian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HygM3516kVTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "76cf6555-ae63-418e-fea7-be7944a00933"
      },
      "source": [
        "# Korean HateSpeech Dataset\n",
        "!wget https://github.com/kocohub/korean-hate-speech/raw/master/labeled/train.tsv\n",
        "!wget https://github.com/kocohub/korean-hate-speech/raw/master/labeled/dev.tsv\n",
        "!wget https://github.com/kocohub/korean-hate-speech/raw/master/test.no_label.tsv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-11 20:00:57--  https://github.com/kocohub/korean-hate-speech/raw/master/labeled/train.tsv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/labeled/train.tsv [following]\n",
            "--2020-09-11 20:00:57--  https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/labeled/train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 913546 (892K) [text/plain]\n",
            "Saving to: ‘train.tsv’\n",
            "\n",
            "train.tsv           100%[===================>] 892.13K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2020-09-11 20:00:57 (11.9 MB/s) - ‘train.tsv’ saved [913546/913546]\n",
            "\n",
            "--2020-09-11 20:00:57--  https://github.com/kocohub/korean-hate-speech/raw/master/labeled/dev.tsv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/labeled/dev.tsv [following]\n",
            "--2020-09-11 20:00:58--  https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/labeled/dev.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 54903 (54K) [text/plain]\n",
            "Saving to: ‘dev.tsv’\n",
            "\n",
            "dev.tsv             100%[===================>]  53.62K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-09-11 20:00:58 (2.48 MB/s) - ‘dev.tsv’ saved [54903/54903]\n",
            "\n",
            "--2020-09-11 20:00:58--  https://github.com/kocohub/korean-hate-speech/raw/master/test.no_label.tsv\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/test.no_label.tsv [following]\n",
            "--2020-09-11 20:00:58--  https://raw.githubusercontent.com/kocohub/korean-hate-speech/master/test.no_label.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96108 (94K) [text/plain]\n",
            "Saving to: ‘test.no_label.tsv’\n",
            "\n",
            "test.no_label.tsv   100%[===================>]  93.86K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-09-11 20:00:58 (3.68 MB/s) - ‘test.no_label.tsv’ saved [96108/96108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jay19SdzlFbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "59aa7cab-df2a-4b5d-db92-79e437fa9a9a"
      },
      "source": [
        "!pip install soynlp\n",
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\u001b[K     |████████████████████████████████| 419kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->soynlp) (0.16.0)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 15.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 24.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 28.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=aabfa91cf8f3276906a101b07984aa7392f981f66e07464e8013128afcb53370\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YWzYs80oO7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "eeca53fd-06d6-4d65-eaf1-4355ee58465e"
      },
      "source": [
        "# DistilKoBERT: Lightweight version of KoBERT\n",
        "!git clone https://github.com/monologg/DistilKoBERT.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DistilKoBERT'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 544 (delta 95), reused 126 (delta 48), pack-reused 365\u001b[K\n",
            "Receiving objects: 100% (544/544), 531.66 KiB | 5.02 MiB/s, done.\n",
            "Resolving deltas: 100% (302/302), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwBuhtLikmnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "train_dataset = pd.read_csv('train.tsv', sep='\\t')\n",
        "val_dataset = pd.read_csv('dev.tsv', sep='\\t')\n",
        "test_dataset = pd.read_csv('test.no_label.tsv', sep='\\t')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttnp_ZhfObSJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6g0XbEPk32z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "78aa0c87-2b5b-4cd4-e438-0cffe3aee9ea"
      },
      "source": [
        "train_dataset.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>contain_gender_bias</th>\n",
              "      <th>bias</th>\n",
              "      <th>hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3484</th>\n",
              "      <td>세경씨 그렇게 안봤는데 진짜 무서운사람이네 세경씨</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>느무 재미 없다.</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3982</th>\n",
              "      <td>아니 왜 범죄자가 기어나오냐고 자꾸</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>hate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>641</th>\n",
              "      <td>광희야 방탄 대신 군대 10년만 더 갔다오자 애국하는거야</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2094</th>\n",
              "      <td>돈없어봐라ㅋㅋ ㅈㄹ들떠세요</td>\n",
              "      <td>False</td>\n",
              "      <td>none</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             comments  contain_gender_bias  bias       hate\n",
              "3484      세경씨 그렇게 안봤는데 진짜 무서운사람이네 세경씨                False  none       none\n",
              "1827                        느무 재미 없다.                False  none       none\n",
              "3982              아니 왜 범죄자가 기어나오냐고 자꾸                False  none       hate\n",
              "641   광희야 방탄 대신 군대 10년만 더 갔다오자 애국하는거야                False  none  offensive\n",
              "2094                   돈없어봐라ㅋㅋ ㅈㄹ들떠세요                False  none  offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqvdahnkrmYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da9c67de-5841-47cd-e6df-2f18d47dba56"
      },
      "source": [
        "train_dataset['comments'].apply(len).mean()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.710739614994935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnpF05fylDDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from soynlp.normalizer import *\n",
        "\n",
        "# remove emoticons and repeated characters like \"ㅋㅋㅋ\"\n",
        "def clean(text):\n",
        "  text = text.map(lambda x: emoticon_normalize(x, num_repeats=3))\n",
        "  text = text.map(lambda x: repeat_normalize(x, num_repeats=2))\n",
        "  return text\n",
        "\n",
        "# map 1 if offensive or hate\n",
        "#     0 if none\n",
        "def map_hate(hate_value):\n",
        "  mapping = {\n",
        "      'none': 0,\n",
        "      'offensive': 1,\n",
        "      'hate': 1\n",
        "  }\n",
        "  hate_value = hate_value.map(lambda x: mapping.get(x))\n",
        "  return hate_value\n",
        "\n",
        "train_dataset['comments'] = clean(train_dataset['comments'])\n",
        "val_dataset['comments'] = clean(val_dataset['comments'])\n",
        "test_dataset['comments'] = clean(test_dataset['comments'])\n",
        "\n",
        "train_dataset['hate'] = map_hate(train_dataset['hate'])\n",
        "val_dataset['hate'] = map_hate(val_dataset['hate'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s88DsmpymZ_1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "a607e5c62425421c8a44d4ebd5beb896",
            "05457b92c98d4b97bc28eefddeb0beb6",
            "8ae4dfa64ec345e8a3a81cf7a956437a",
            "99f5f3dd94cb4a748bcb4d8d2384f2a2",
            "7baba7b4193346d29a17ea97c0e3735a",
            "c4052e2623404dd4bb9b4ec255bc19cf",
            "5a6b70438d4843baad6ab6c9e928d87a",
            "8958d0b3797f430e8fde1be470448fbd",
            "da454c10f10e4fbba5c50c804ee53806",
            "e8518f8009a0439cb203fcee4d689123",
            "129b5df777b14773ba3d8ad51a061ffc",
            "bb2ef1f89162461d870ce3af1be929ca",
            "e8858eda43e94cd69fd6e7c6eaf58ae7",
            "c89154234e5b4c26bd9bf8388d403bf4",
            "4da3b853f6624db48df4f73887273b6f",
            "2629d5b97fed45b6bb8a3067af5bd2e0",
            "651035ad5e6b44d0baa189a02d92cc06",
            "b2ce76d54d074969831f312e515e33d4",
            "bc7298213f9845d2aa9df877902a2cc9",
            "ca7dd0c7d1c543c199a6b147fca70355",
            "d453f62c26c742e0955082ddd04ac11f",
            "0a738c20fb7642a1b7582b6f6c09830b",
            "a12fefdf86da42939a4e4b2d2b0bf034",
            "dfaea0b84d3c4a40a1179c0483cd3082",
            "ff042a1a6ad2405fac06a8df93ae9b7b",
            "551ac9ccbffa4d17a937d74e64335728",
            "fafe51672b8e4870a532bee729fffa6d",
            "16838df5b306474b958fafd5df027f63",
            "d7a4397b83e640f0bb60fa2b7b336c37",
            "00db2e740dd54198b1cec893c330d139",
            "e29e567fe8194e6886a268bf6d2fb197",
            "fcb38bbd771f45b39683a3f58a61fe80"
          ]
        },
        "outputId": "f2edda60-33c8-400c-f952-07d75e93fa2a"
      },
      "source": [
        "# Load DistilKoBERT tokenizer\n",
        "import transformers\n",
        "from DistilKoBERT.tokenization_kobert import KoBertTokenizer\n",
        "\n",
        "distilbert_model = transformers.DistilBertModel.from_pretrained('monologg/distilkobert')\n",
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a607e5c62425421c8a44d4ebd5beb896",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=441.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da454c10f10e4fbba5c50c804ee53806",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=113629967.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "651035ad5e6b44d0baa189a02d92cc06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff042a1a6ad2405fac06a8df93ae9b7b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUKRT-DXtwij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "70d205cb-3bc3-4505-bae1-142afe854bca"
      },
      "source": [
        "tokenizer.tokenize(\"근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁근',\n",
              " '데',\n",
              " '▁',\n",
              " '만원',\n",
              " '이',\n",
              " '하는',\n",
              " '▁현금',\n",
              " '결제',\n",
              " '만',\n",
              " '▁',\n",
              " '하라고',\n",
              " '▁써',\n",
              " '놓',\n",
              " '은',\n",
              " '집',\n",
              " '▁우리나라',\n",
              " '에',\n",
              " '▁엄',\n",
              " '청',\n",
              " '▁많은',\n",
              " '데']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mDuKa--uEqe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e62844f7-f9ec-43da-e158-ece83beb4bbd"
      },
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# convert to BERT-understandable data\n",
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "\n",
        "    SEQ_LEN = 64\n",
        "    \n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True, truncation=True)\n",
        "       \n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        \n",
        "        segment = [0]*SEQ_LEN\n",
        " \n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        \n",
        "        targets.append(data_df[LABEL_COLUMN][i])\n",
        " \n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        " \n",
        "    return [tokens, masks, segments], targets\n",
        "\n",
        "def load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y\n",
        " \n",
        "SEQ_LEN = 64\n",
        "BATCH_SIZE = 32\n",
        "DATA_COLUMN = \"comments\"\n",
        "LABEL_COLUMN = \"hate\"\n",
        " \n",
        "train_x, train_y = load_data(train_dataset)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/7896 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 7896/7896 [00:02<00:00, 3334.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmavXxTOyItr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "701f523b-e01b-4bca-d592-b5b86e4dce57"
      },
      "source": [
        "test_x, test_y = load_data(val_dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/471 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 471/471 [00:00<00:00, 3227.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVvUADvdzBSI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "fcf9cb6e-da0d-4f4d-be2a-37ad4d19fbc7"
      },
      "source": [
        "from keras.optimizers import *\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*8, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08)\n",
        "\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "def create_hate_bert():\n",
        "  model = transformers.TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
        "\n",
        "  bert_outputs = bert_outputs[1]\n",
        "\n",
        "  hate_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n",
        "  hate_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(hate_drop)\n",
        "  hate_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], hate_first)\n",
        "\n",
        "  return hate_model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.110.193.10:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.110.193.10:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9KrlXFx0YhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "af04eed5-febc-46d7-c074-2eeb4b5cb25b"
      },
      "source": [
        "with strategy.scope():\n",
        "  hate_model = create_hate_bert()\n",
        "  hate_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n",
        "  hate_model.fit(train_x, train_y, epochs=6, shuffle=True, batch_size=64, validation_data=(test_x, test_y))\n",
        "  # hate_model.save('hate_model.h5') \n",
        "\n",
        "print(hate_model.summary())\n",
        "loss, acc = hate_model.evaluate(test_x, test_y, verbose=2)\n",
        "print('Model accuracy: {:5.2f}%'.format(100*acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "  2/124 [..............................] - ETA: 45:24 - loss: 0.7116 - accuracy: 0.4531  WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0913s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0913s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - ETA: 0s - loss: 0.6875 - accuracy: 0.5408WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_test_batch_end` time: 0.0267s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_test_batch_end` time: 0.0267s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "124/124 [==============================] - 103s 834ms/step - loss: 0.6875 - accuracy: 0.5408 - val_loss: 0.6603 - val_accuracy: 0.5987\n",
            "Epoch 2/6\n",
            "124/124 [==============================] - 13s 101ms/step - loss: 0.6780 - accuracy: 0.5640 - val_loss: 0.6688 - val_accuracy: 0.5541\n",
            "Epoch 3/6\n",
            "124/124 [==============================] - 12s 100ms/step - loss: 0.6385 - accuracy: 0.6320 - val_loss: 0.5542 - val_accuracy: 0.7091\n",
            "Epoch 4/6\n",
            "124/124 [==============================] - 12s 99ms/step - loss: 0.5694 - accuracy: 0.7077 - val_loss: 0.5223 - val_accuracy: 0.7495\n",
            "Epoch 5/6\n",
            "124/124 [==============================] - 12s 100ms/step - loss: 0.5193 - accuracy: 0.7392 - val_loss: 0.4741 - val_accuracy: 0.7792\n",
            "Epoch 6/6\n",
            "124/124 [==============================] - 12s 100ms/step - loss: 0.4762 - accuracy: 0.7748 - val_loss: 0.5972 - val_accuracy: 0.7176\n",
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model_1 (TFBertModel)   ((None, 64, 768), (N 92186880    input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_75 (Dropout)            (None, 768)          0           tf_bert_model_1[0][1]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            769         dropout_75[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 92,187,649\n",
            "Trainable params: 92,187,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_test_batch_end` time: 0.0244s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_test_batch_end` time: 0.0244s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "15/15 - 4s - loss: 0.5972 - accuracy: 0.7176\n",
            "Model accuracy: 71.76%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb2NQZE1_RF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hate_model.save_weights('/content/hate_bert_model.h5')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVVo4tBz2Clk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_convert_data(data):\n",
        "    tokens, masks, segments = [], [], []\n",
        "    token = tokenizer.encode(data, max_length=SEQ_LEN, pad_to_max_length=True, truncation=True)\n",
        "    \n",
        "    num_zeros = token.count(0) \n",
        "    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \n",
        "    segment = [0]*SEQ_LEN\n",
        "\n",
        "    tokens.append(token)\n",
        "    segments.append(segment)\n",
        "    masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "def predict_comment(sentence):\n",
        "    data_x = sentence_convert_data(sentence)\n",
        "    predict = hate_model.predict(data_x)\n",
        "    predict_value = np.ravel(predict)\n",
        "    predict_answer = np.round(predict_value,0).item()\n",
        "    \n",
        "    if predict_answer:\n",
        "      print(\"*\", sentence, \"(악플 확률 : %.2f)\" % predict_value)\n",
        "    else:\n",
        "      print(sentence, \"(악플 확률 : %.2f)\" % predict_value)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvJfaMS95oKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f38193a-a541-41fc-b27d-0d3c7aa97765"
      },
      "source": [
        "# test set prediction\n",
        "for comment in test_dataset['comments'][:100]:\n",
        "  predict_comment(comment)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ (악플 확률 : 0.44)\n",
            "둘다 넘 좋다~행복하세요 (악플 확률 : 0.09)\n",
            "* 근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데 (악플 확률 : 0.70)\n",
            "원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요 (악플 확률 : 0.08)\n",
            "장현승 얘도 참 이젠 짠하다... (악플 확률 : 0.35)\n",
            "신선하게 웃긴ㅋㅋㅋ시 동엽신~~!! 장소연님은 진짜 조선족인가 착각할정도로 말투가 리얼하네요 (악플 확률 : 0.14)\n",
            "* 누군데 얘네? (악플 확률 : 0.64)\n",
            "* 하자 인생들 모아다가 방송에 내보내고, 덜 하자가 교정해서 장사 풀리게 해주는 감동 스토리 백하자의 골목식당. 호텔 말고 그냥 하자 거리를 하나 열어서 거기다 하자 인생들 교화소를 만들지... 왜 저러고 살까... (악플 확률 : 0.56)\n",
            "진짜 라디오 스타 노래한거 보세요 홍진영은비비지도 못함 (악플 확률 : 0.35)\n",
            "* 쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 기어나올 생각말고 하던대로 그냥 조용히 살어라! 잠재적 살인마. (악플 확률 : 0.88)\n",
            "* 질투 ㅈㄴ 하네 뚱땡이년들 수지보다는 훨씬낫다 (악플 확률 : 0.92)\n",
            "안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고??눈 감았다가 뜨는 동영상 올려보시죠...정작 안검하수 있는 분들은 수술해도 부작용 때문에.. 눈꺼플 잘 못감거든요.. (악플 확률 : 0.21)\n",
            "그건 불가능해. 그냥 은퇴해서 평범하게 살아라. 언제가 될지는 모르지만, 시기가 문제일뿐... 망가지는건 분명하다. 연예계에서 사는거보다 일반인으로 사는게 행복할거다. (악플 확률 : 0.32)\n",
            "약사는 역시 김재환이지 (악플 확률 : 0.10)\n",
            "* 발연기 현빈 국밥장인 팬들만 물고 빠는 ㅋㅋㅋ (악플 확률 : 0.77)\n",
            "* 골목살리고 지가하는 체인점 다입점해서. 때돈벌고. 피디 술사주고. 지가 음식점 체인사업을 때려쳐야 진정성이보이는거지 (악플 확률 : 0.72)\n",
            "* 참나 종원아 말 함부로 하는거 아니다니네 체인점 개판인데가 한두군데가 아니다가격은 드릅게 비싸요 (악플 확률 : 0.64)\n",
            "근데 팬들이 나서야되는데 왜 일반인들이 연애할수도 있지 이 ㅈㄹ ㅋㅋㅋ 내가 봐도 팬들 개빡치겠구만 (악플 확률 : 0.37)\n",
            "* 여자같다 어깨도 너무좁고 뜨긴글럿네 (악플 확률 : 0.90)\n",
            "좋게좋게 해결되시길 (악플 확률 : 0.08)\n",
            "김성주 겁나 비호감인데 잘나가네. 방송을 잘하나베 (악플 확률 : 0.43)\n",
            "살빠진 마닷 같애 (악플 확률 : 0.47)\n",
            "* 삼성다니던 대기업 사원이 애플 스티브잡스죽었다고 #그와의만남을 기억하며 이러고다는꼴이네 ㅋㅋㅋ짜 ㅈㄹ 유분수지 (악플 확률 : 0.90)\n",
            "이아지매는 본인화장은 못하던데.. (악플 확률 : 0.46)\n",
            "한효주가 뭐가 아쉬워서 사람 많은 클럽에서 침까지 질질 흘리며 콧물까지흘리며 마약을 했을까. 아니면 빨리 법적대응 해야지 이미지 너무 하락하겠다.한효주같은A급 연예인이 진짜 사람 많은곳에서 그랬다면 충격인데. (악플 확률 : 0.35)\n",
            "윤정언니 힘내세요~ 앞으로 꽃길만걷기를... (악플 확률 : 0.08)\n",
            "* 페미들 ㄹㅇ 토나온다 (악플 확률 : 0.66)\n",
            "안타깝네요ㅜㅜ좋아하던 배우인데ㅜ (악플 확률 : 0.08)\n",
            "그래 자랑이다. 개독이 얼마나 무서운데 얼마나 갈지 함 두고보자. (악플 확률 : 0.28)\n",
            "축하합니다! 예쁘게 잘~사세요~ (악플 확률 : 0.08)\n",
            "* 여기 성별에 댓글만봐도 한남 믿거할수있겠다 (악플 확률 : 0.69)\n",
            "* 성내동이 살려 냈군여 (악플 확률 : 0.64)\n",
            "존못인데 연기자로서는... (악플 확률 : 0.10)\n",
            "끝낼때도 됐지 요즘같은 분위기엔 성드립 잘못쳤다가 난리. 그동안 잘봤습니다 (악플 확률 : 0.12)\n",
            "살아봐라 행복은 성적순이다 (악플 확률 : 0.09)\n",
            "사진 굉장히 인상적이고 특이하네요~ (악플 확률 : 0.09)\n",
            "한나라당 소속 국회의원이었죠. (악플 확률 : 0.31)\n",
            "갑자기 빌푸 보고 싶다 ㅋㅋㅋ (악플 확률 : 0.33)\n",
            "* 제2 3의 피해자가 안나오면 꽃뱀인거네 남자란 족속들은 그냥 할수 있으면 하는구나인간이란 종자가 드럽다 (악플 확률 : 0.92)\n",
            "* 하루 아침에 자식을 잃은 부모다 남편선처없다 잘하고 있다했더니 지금 유가족 반박이 문제냐 그자리에 없었다 죄송하다 읖조려야 정상이다 충고하자면 완급조절잘해라 (악플 확률 : 0.53)\n",
            "송사끝나서 후련한 마음에 동남아 좀 갔다고 뭐 문제라도 있음? (악플 확률 : 0.49)\n",
            "* 그래서 욕안먹을라고 나이 서른에 국대은퇴했냐 (악플 확률 : 0.84)\n",
            "* 개듣보 두마리 (악플 확률 : 0.64)\n",
            "나만 악플? 직선적인글 쓴거 아니네 내 글이 길어서인가본데 블로그엔 한마디 말도 못하면서 만만한게 뉴스댓글인지 여기도 연예뉴스댓글 페지하면 좋겠다 (악플 확률 : 0.33)\n",
            "어느 순간부터 문득 팔자 참 좋다 라고 생각이 들면서 지금은 안보게 됨.. 잘들 놀러다니셔 (악플 확률 : 0.15)\n",
            "* 성폭행 몇번 했다고 이런 난리를 치면 오징어들은 뭐하고 사냐. 평생 휴지랑 함께하는 독거인생들이네. ㄷ ㄷ (악플 확률 : 0.91)\n",
            "완전 처음보는 얼굴이네 (악플 확률 : 0.09)\n",
            "명을 달리한지 얼마 되지도 않은 멤버를 상업적으로 이용하는 모습이 그렇게 좋게 보이지는 않네요. 연예계 참 매정하네요. (악플 확률 : 0.18)\n",
            "* 광고 많이 찍어라. 요즘 본중 제일 낫다. (악플 확률 : 0.54)\n",
            "* 계정 턴 해커가 문젠데 이놈의 감성의 나라는 오히려 털린 사람을 가해자로 몰고있네 ㅋㅋㅋ 니들도 조만간이다~ (악플 확률 : 0.90)\n",
            "* 여자는 역시 나이어린게최고지 30살넘음 폐기물 ㅇㅈ? (악플 확률 : 0.91)\n",
            "누굽니까? 이 무명배우는 (악플 확률 : 0.39)\n",
            "* 티아라 말고 티야라 라고 바꿔라 (악플 확률 : 0.80)\n",
            "* 몸 괜찮아 졌으면 군대 부터 갔다 와야 하는거 아닌가? (악플 확률 : 0.63)\n",
            "슈가대디 해명하라 (악플 확률 : 0.10)\n",
            "* 아따 그라제 남자가 여자 만지면 성추행 여자가 남자만지면 장난이제 ~~암 그라제잉~~ (악플 확률 : 0.88)\n",
            "설마20년 차이나는건 아니겠죠~~~ㅠㅠ 범죄입니다 (악플 확률 : 0.38)\n",
            "* ■ 뭔 ㅆl 뱔 이상아 따위한테 악플을 다냐 ㅉㅉ 존나 아이유대 있고 더 가치있는 애들 많잖아. (악플 확률 : 0.70)\n",
            "치열한 보라식당 방송분량 너무하다..치열한 보라식당 좀 보여주지.. (악플 확률 : 0.30)\n",
            "* 공효진 고생이다 에휴 사과를 뭐하러하냐. 그냥 여성인권에 관심있어요라고 한마디하면 뭔짓을 저질러도 꼴페미들이 도와줄꺼야 ㅋㅋ 꼴페미들은 논리 뭐 이런거없거든 ㅋㅋ (악플 확률 : 0.89)\n",
            "* 만약 웬디가 이 일로 자살까지 가면 sbs가 죽인 살인이나 마찬가지다 (악플 확률 : 0.57)\n",
            "* 가로수길에서 나한테 라이터 빌려간 누나... (악플 확률 : 0.63)\n",
            "* 절라더 애들은 하는 말이 다 거짓말임 (악플 확률 : 0.59)\n",
            "당최 뭔 내요인지 ㅇ (악플 확률 : 0.46)\n",
            "god 팬을 떠나서 이 방송 너무 좋은데 기사 좀 많이 내줘요 ㅠㅠ. 뭔가 내 친구들이랑 같이 가보고 싶은 마음을 갖게 함 ㅠㅠ (악플 확률 : 0.10)\n",
            "* 요즘폭로가유행인가 ㅋㅋ (악플 확률 : 0.70)\n",
            "* 아 시발 더러워 ㅡㅡㅋ 제발 늙은것들은 젊은 사람 탐하지마라 남녀 모두 ㅡㅡ 진짜 더러워 (악플 확률 : 0.90)\n",
            "3세대 아이돌들의 몰락 (악플 확률 : 0.28)\n",
            "* 위안부 감성팔이 그만좀해라;;; 자연의 섭리처럼 제국주의 시대때는 어쩔수가없었다 (악플 확률 : 0.90)\n",
            "스포 오지네 (악플 확률 : 0.09)\n",
            "우와 남자배우가 먼저 저렇게 나서주다니 진짜 멋지네요.. 차별을 인정하고 바꾸어나가려고 하는 모습이 부럽기도하네요 (악플 확률 : 0.12)\n",
            "* 결혼을 왜하냐 불쌍한 것 (악플 확률 : 0.62)\n",
            "발연기끼리 만나서 이게 바로 발연기다라는걸 제대로 보여주는중 (악플 확률 : 0.31)\n",
            "근데 가끔 고정멤버들이 게스트들 후려칠때 얼탱이없음 ^^ (악플 확률 : 0.13)\n",
            "김준연이가 걸그룹 여자친구랑 박보영 팬이라 둘다 출연한거고 홍보때문에는 연예인들 많이 안출연시킴. (악플 확률 : 0.32)\n",
            "3년 봅니다~^^ (악플 확률 : 0.09)\n",
            "* 우한 화이팅! 중국 화이팅! 한국연예인도 화이팅! 한국은 연예인 자살율 1위라는데 못잡아먹어서 안달난 국민성때문에 ㅉㅉ (악플 확률 : 0.59)\n",
            "* 에휴....남자는 나이 많아도 상관없지만 여자는 ....ㅠㅠ1년 바짝 난자 모으시는데 집중하시고 시술 성공하시길!! (악플 확률 : 0.51)\n",
            "와꾸 40살이라 해도 믿겠는데 (악플 확률 : 0.37)\n",
            "예쁘기만 한데 왜케들 비판적이신지.. 괜히 질투나고 부러워서 그러는듯 그렇게 느껴지네요 (악플 확률 : 0.11)\n",
            "* 염병한다 ㅋㅋㅋ 가수도 정떨어지겠다 팬 행태에 (악플 확률 : 0.83)\n",
            "* 이쁘지도않은 엉덩이를 펑퍼짐한 엉덩이를 팬들 눈버렸잖아요 사람들이 다좋아할거란 생각은 뭘까 관여하지말아 공주병 말기구나 (악플 확률 : 0.55)\n",
            "탁재훈 역시 재밌ㅋㅋㅋ 예능의 최고수인데 방송에서 못보고 있는게 아쉽다 아는형님 인지 거기 있는 애들보다 탁재훈이나 신정환 이런 형님들이 백만배 더 웃기는데 재능을 썩히고 있는거 아까워 미우새에 탁재훈 계속 봤으면 좋겠다 (악플 확률 : 0.35)\n",
            "강동구에 선사시대축제에 이번주에 오던데~~~설마 3500주고 부른건 아니겠지~~~강동구예산 없다. (악플 확률 : 0.34)\n",
            "느븐틴 관심도 없고 재미도 없고 우글우글.. 꺼져라 (악플 확률 : 0.46)\n",
            "그렇게 큰 비중도 아니고 매회 나오는 것도 아니고, 살을 찌우면서까지 할 배역인가. 대사 한마디 없고. 큰 연기력이 필요한 것도 아니고, (악플 확률 : 0.23)\n",
            "탁재훈 웃기는 재능은 진짜 타의추종을 불허한다고 생각한다 말할때마다 빵빵 터지고 너무 웃김 유머센스 대박 (악플 확률 : 0.11)\n",
            "* 뭔 중국인 ? 저 년놈들 조선족이지 ? (악플 확률 : 0.92)\n",
            "설령 돈을어느정도 갚더라도 마닷캐스팅하는 pd는 없겠지 (악플 확률 : 0.46)\n",
            "정준영만 나가리되는건가?? 몸통이 어떻길래??? (악플 확률 : 0.46)\n",
            "* 걍 제발 연예인들 보고 즐기고 예능으로 보라범죄 저지른것 아니면 배놔라 감놔라 악플달지말고ᆢ너희 가족은 완벽하냐? 하여간 울 나라 섹히들 남말은 잘도해 자기 앞가림도 못하면서 ᆢ (악플 확률 : 0.92)\n",
            "* 44살인데 임신 가능한가요? (악플 확률 : 0.67)\n",
            "* 기사의 내용과는 무관하지만... 못생겼거나 성적 매력이 없는 여자들은 모두 전재산 국고로 환수 시키고 무인도에 갖다 버려져야 마땅하다 (악플 확률 : 0.87)\n",
            "두분다 결혼하신줄 알았는데 미혼이시네요^^좋은결과있었음 ㅋ~~~ (악플 확률 : 0.09)\n",
            "* 인기가수면 공인인데, 화난다고 행패부리면 되냐.. 직원들이 무슨 죄임? 수입차 본사에서 잘못 만들어서 문제인게지.. 검색해보니 가수 이름은 잘 모르겠던데, 소속그룹은 인기그룹이었다. 93년도에 인기 좋았지.. (악플 확률 : 0.56)\n",
            "* 인성부터...연말시상식에 술처먹고 노숙자 옷입고 인상만쓰고 (악플 확률 : 0.72)\n",
            "* 동명이인이면 평소처럼 찐따마냥 있어라.. 괜히 언플해서 떠볼 생각 말고.. 관종도 아니고 이딴 듣보가 왜 설치는거야.. 어휴 (악플 확률 : 0.62)\n",
            "하 .... 다시보기..여진구에게세 왜 안영미가 잠시 보였지..? (악플 확률 : 0.31)\n",
            "왜이제서야 확뜨신겁니꼬.넘웃기고.여자들한테인기많을스타일인데 7년이나한결같이연애를ㅡㅡ (악플 확률 : 0.40)\n",
            "아이고 아이고~~ 만인의 연인였는데...그래두 짝을 만났으니 축하~~~ (악플 확률 : 0.12)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}